---
phase: 01-core-reliability
plan: "04"
type: execute
wave: 3
depends_on:
  - "01-02"
  - "01-03"
files_modified:
  - syntho_hive/interface/synthesizer.py
  - tests/test_e2e_single_table.py
  - tests/test_serialization.py
  - tests/test_seed_regression.py
autonomous: true
requirements:
  - CONN-04
  - TEST-01
  - TEST-03
  - TEST-05

must_haves:
  truths:
    - "save_to_hive() with database name containing ';', '--', or special characters raises SchemaError before any spark.sql() call is made"
    - "save_to_hive() with database name matching ^[a-zA-Z0-9_]+$ proceeds normally"
    - "pytest tests/test_e2e_single_table.py passes: CTGAN fits on a 200-row dataset in <= 5 epochs, samples 50 rows with correct column names and no all-null columns"
    - "pytest tests/test_serialization.py passes: fit → save directory → load into fresh CTGAN → sample returns a DataFrame with correct columns"
    - "pytest tests/test_seed_regression.py passes: two independent CTGAN.fit(seed=42).sample(100, seed=7) runs produce bit-identical DataFrames"
    - "pytest tests/ -x runs without new failures introduced by Phase 1 changes"
  artifacts:
    - path: "syntho_hive/interface/synthesizer.py"
      provides: "SQL injection prevention in save_to_hive() via regex allowlist"
      contains: "_SAFE_IDENTIFIER"
      min_lines: 5
    - path: "tests/test_e2e_single_table.py"
      provides: "TEST-01 single-table end-to-end test"
      contains: "def test_single_table_e2e"
      min_lines: 30
    - path: "tests/test_serialization.py"
      provides: "TEST-03 serialization round-trip test"
      contains: "def test_serialization_round_trip"
      min_lines: 30
    - path: "tests/test_seed_regression.py"
      provides: "TEST-05 bit-identical seed regression test"
      contains: "def test_seed_produces_identical_output"
      min_lines: 25
  key_links:
    - from: "syntho_hive/interface/synthesizer.py save_to_hive()"
      to: "_SAFE_IDENTIFIER regex"
      via: "re.compile(r'^[a-zA-Z0-9_]+$').match(target_db)"
      pattern: "_SAFE_IDENTIFIER\\.match"
    - from: "tests/test_serialization.py"
      to: "syntho_hive/core/models/ctgan.py CTGAN.save() + load()"
      via: "model.save(tmp_path) then fresh_model.load(tmp_path).sample()"
      pattern: "model\\.load"
    - from: "tests/test_seed_regression.py"
      to: "syntho_hive/core/models/ctgan.py CTGAN.fit(seed=42)"
      via: "two independent CTGAN instances, same seed, pd.testing.assert_frame_equal"
      pattern: "assert_frame_equal"
---

<objective>
Patch save_to_hive() SQL injection and write the three test files (TEST-01, TEST-03, TEST-05) that validate all Phase 1 reliability fixes.

Purpose: CONN-04 closes the SQL injection vulnerability that exists in the current save_to_hive(). The three test files create a permanent regression harness — any future regression in serialization, reproducibility, or basic training immediately fails these tests.
Output: Patched synthesizer.py with regex identifier validation; three new test files that all pass.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-core-reliability/01-CONTEXT.md
@.planning/phases/01-core-reliability/01-RESEARCH.md
@.planning/phases/01-core-reliability/01-01-SUMMARY.md
@.planning/phases/01-core-reliability/01-02-SUMMARY.md
@.planning/phases/01-core-reliability/01-03-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Patch save_to_hive() with SQL injection allowlist validation</name>
  <files>syntho_hive/interface/synthesizer.py</files>
  <action>
Read `syntho_hive/interface/synthesizer.py` fully to find the `save_to_hive()` method and understand its current implementation — specifically: what parameters it accepts, how it calls `spark.sql()`, and whether it validates the database or table names at all.

**Add a module-level compiled regex** at the top of synthesizer.py (after imports):

```python
import re
_SAFE_IDENTIFIER = re.compile(r'^[a-zA-Z0-9_]+$')
```

If `import re` is already present, do not add it again.

**At the start of save_to_hive()**, before any Spark operations, add the following validation:

```python
# Validate database name against allowlist before any SQL interpolation
# Raises SchemaError immediately — no Spark context touched for invalid names
if not _SAFE_IDENTIFIER.match(target_db):
    raise SchemaError(
        f"SchemaError: Database name '{target_db}' contains invalid characters. "
        f"Only letters, digits, and underscores [a-zA-Z0-9_] are allowed. "
        f"This validation prevents SQL injection via unsanitized user input."
    )

# Validate table names from synthetic_data keys
for table_name in synthetic_data:
    if not _SAFE_IDENTIFIER.match(str(table_name)):
        raise SchemaError(
            f"SchemaError: Table name '{table_name}' contains invalid characters. "
            f"Only letters, digits, and underscores [a-zA-Z0-9_] are allowed."
        )
```

`target_db` is the database name parameter — confirm the exact parameter name by reading the method signature. If the parameter is named differently (e.g., `database`, `db_name`), use that name.

Ensure `from syntho_hive.exceptions import SchemaError` is present at the top of synthesizer.py (Plan 01 added this — confirm it exists, add if missing).

**Do not modify the rest of save_to_hive()** — only add the validation block at the top.
  </action>
  <verify>
```bash
python -c "
from syntho_hive.interface.synthesizer import Synthesizer
from syntho_hive.exceptions import SchemaError

# Synthesizer needs config to instantiate — find the right way to create a minimal one
# This tests the save_to_hive validation without a Spark session
# We test the module-level regex directly since Spark is not available in this env

import re
# Import the compiled regex from synthesizer module
import syntho_hive.interface.synthesizer as syn_mod
assert hasattr(syn_mod, '_SAFE_IDENTIFIER'), 'Missing _SAFE_IDENTIFIER in synthesizer.py'

regex = syn_mod._SAFE_IDENTIFIER
# Valid names
assert regex.match('my_database'), 'Valid name should match'
assert regex.match('customers_2024'), 'Valid name should match'
assert regex.match('DB'), 'Valid name should match'
# Invalid names
assert not regex.match('my-database'), 'Hyphen should fail'
assert not regex.match('db; DROP TABLE'), 'Injection should fail'
assert not regex.match('db--comment'), 'SQL comment should fail'
assert not regex.match(''), 'Empty string should fail'
assert not regex.match('db name'), 'Space should fail'
print('SQL injection prevention regex OK')
"
```

Also grep to confirm save_to_hive raises SchemaError:
```bash
grep -n "SchemaError" /Users/arnavdadarya/FedEx/SynthoHive/syntho_hive/interface/synthesizer.py | head -10
grep -n "_SAFE_IDENTIFIER" /Users/arnavdadarya/FedEx/SynthoHive/syntho_hive/interface/synthesizer.py | head -5
```
  </verify>
  <done>
- `_SAFE_IDENTIFIER = re.compile(r'^[a-zA-Z0-9_]+$')` exists at module level in synthesizer.py
- save_to_hive() validates database name and all table names before any spark.sql() call
- Invalid names (with hyphens, spaces, semicolons, SQL comments) raise SchemaError
- Valid names (letters, digits, underscores) proceed normally
  </done>
</task>

<task type="auto">
  <name>Task 2: Write TEST-01, TEST-03, TEST-05 test files</name>
  <files>
    tests/test_e2e_single_table.py
    tests/test_serialization.py
    tests/test_seed_regression.py
  </files>
  <action>
Read the existing tests in `tests/` to understand the current test patterns (conftest.py if present, fixture conventions, import patterns). Read `syntho_hive/interface/config.py` to understand how `Metadata` is constructed and how `add_table()` works. Read `syntho_hive/core/models/ctgan.py` to confirm the CTGAN constructor signature.

**Important:** Check whether `tests/` has a `conftest.py` with shared fixtures. If shared fixtures exist (e.g., `small_dataset`, `meta`) and conflict with the ones you're defining, import from conftest instead of redefining. If not, define them locally in each test file.

Also read `tests/test_models.py` to see how existing tests construct CTGAN instances — copy the import pattern and constructor arguments exactly.

**Write `tests/test_e2e_single_table.py` (TEST-01):**

```python
"""TEST-01: Single-table end-to-end test — fit → sample → basic validation."""
import pandas as pd
import numpy as np
import pytest
from syntho_hive.core.models.ctgan import CTGAN
from syntho_hive.interface.config import Metadata


@pytest.fixture
def small_dataset():
    np.random.seed(0)
    return pd.DataFrame({
        "id": range(200),
        "age": np.random.randint(18, 80, 200),
        "income": np.random.exponential(50_000, 200),
        "city": np.random.choice(["NY", "SF", "LA", "CHI"], 200),
    })


@pytest.fixture
def meta():
    m = Metadata()
    m.add_table("customers", pk="id")
    return m


def test_single_table_e2e(small_dataset, meta):
    """Fit a CTGAN model on a small dataset, sample, and verify output shape."""
    model = CTGAN(
        meta,
        batch_size=32,
        epochs=3,
        embedding_dim=16,
        generator_dim=(32, 32),
        discriminator_dim=(32, 32),
    )
    model.fit(small_dataset, table_name="customers", seed=42)
    result = model.sample(50, seed=7)

    assert len(result) == 50, f"Expected 50 rows, got {len(result)}"
    # id is the PK — may or may not appear in output depending on config
    # At minimum, non-PK columns must appear
    expected_cols = {"age", "income", "city"}
    missing_cols = expected_cols - set(result.columns)
    assert not missing_cols, f"Missing columns in sample output: {missing_cols}"
    assert not result[list(expected_cols)].isnull().all().any(), \
        "At least one column is entirely null — model output is degenerate"


def test_single_table_fit_does_not_raise(small_dataset, meta):
    """Fit should complete without raising any exception."""
    model = CTGAN(
        meta,
        batch_size=32,
        epochs=2,
        embedding_dim=8,
        generator_dim=(16, 16),
        discriminator_dim=(16, 16),
    )
    # Should not raise
    model.fit(small_dataset, table_name="customers", seed=0)
```

**Write `tests/test_serialization.py` (TEST-03):**

```python
"""TEST-03: Serialization round-trip — fit → save → load → sample without retraining."""
import os
import pandas as pd
import numpy as np
import pytest
from syntho_hive.core.models.ctgan import CTGAN
from syntho_hive.interface.config import Metadata
from syntho_hive.exceptions import SerializationError


@pytest.fixture
def small_dataset():
    np.random.seed(0)
    return pd.DataFrame({
        "id": range(200),
        "age": np.random.randint(18, 80, 200),
        "income": np.random.exponential(50_000, 200),
        "city": np.random.choice(["NY", "SF", "LA"], 200),
    })


@pytest.fixture
def meta():
    m = Metadata()
    m.add_table("customers", pk="id")
    return m


def _make_model(meta):
    return CTGAN(
        meta,
        batch_size=32,
        epochs=3,
        embedding_dim=16,
        generator_dim=(32, 32),
        discriminator_dim=(32, 32),
    )


def test_serialization_round_trip(tmp_path, small_dataset, meta):
    """fit → save to directory → load into fresh CTGAN → sample produces output."""
    model = _make_model(meta)
    model.fit(small_dataset, table_name="customers", seed=42)
    pre_save_sample = model.sample(100, seed=7)

    save_dir = str(tmp_path / "customers")
    model.save(save_dir)

    # Verify directory structure
    required_files = [
        "generator.pt", "discriminator.pt",
        "transformer.joblib", "context_transformer.joblib",
        "embedding_layers.joblib", "data_column_info.joblib",
        "metadata.json",
    ]
    saved_files = os.listdir(save_dir)
    for f in required_files:
        assert f in saved_files, f"Missing checkpoint file: {f}"

    # Cold load — fresh CTGAN instance, NO fit() called
    new_model = _make_model(meta)
    new_model.load(save_dir)
    post_load_sample = new_model.sample(100, seed=7)

    assert len(post_load_sample) == 100, \
        f"Expected 100 rows after load, got {len(post_load_sample)}"
    assert set(post_load_sample.columns) == set(pre_save_sample.columns), \
        f"Column mismatch after load: {set(post_load_sample.columns)} vs {set(pre_save_sample.columns)}"
    # transformer.output_dim must have survived the joblib round-trip
    assert hasattr(new_model.transformer, 'output_dim'), \
        "Loaded transformer missing output_dim — joblib round-trip failed"
    assert new_model.transformer.output_dim > 0, \
        f"Loaded transformer.output_dim={new_model.transformer.output_dim} — invalid"


def test_save_raises_on_existing_path(tmp_path, small_dataset, meta):
    """save() raises SerializationError when path exists and overwrite=False."""
    model = _make_model(meta)
    model.fit(small_dataset, table_name="customers", seed=42)

    save_dir = str(tmp_path / "customers")
    model.save(save_dir)

    with pytest.raises(SerializationError, match="already exists"):
        model.save(save_dir)  # overwrite=False is the default


def test_save_overwrite_true_succeeds(tmp_path, small_dataset, meta):
    """save(overwrite=True) succeeds when path already exists."""
    model = _make_model(meta)
    model.fit(small_dataset, table_name="customers", seed=42)

    save_dir = str(tmp_path / "customers")
    model.save(save_dir)
    model.save(save_dir, overwrite=True)  # Must not raise


def test_load_raises_on_missing_path(meta):
    """load() raises SerializationError when path does not exist."""
    model = _make_model(meta)
    with pytest.raises(SerializationError, match="does not exist"):
        model.load("/tmp/definitely_does_not_exist_syntho_test_path_xyz/")
```

**Write `tests/test_seed_regression.py` (TEST-05):**

```python
"""TEST-05: Seed regression — two independent runs with seed=42 produce bit-identical output."""
import pandas as pd
import numpy as np
import pytest
from syntho_hive.core.models.ctgan import CTGAN
from syntho_hive.interface.config import Metadata


@pytest.fixture
def small_dataset():
    np.random.seed(0)
    return pd.DataFrame({
        "id": range(200),
        "age": np.random.randint(18, 80, 200),
        "income": np.random.exponential(50_000, 200),
        "city": np.random.choice(["NY", "SF", "LA"], 200),
    })


@pytest.fixture
def meta():
    m = Metadata()
    m.add_table("customers", pk="id")
    return m


def _fit_and_sample(dataset, meta, fit_seed: int, sample_seed: int) -> pd.DataFrame:
    """Create a fresh model, fit with the given seed, sample with the given seed."""
    model = CTGAN(
        meta,
        batch_size=32,
        epochs=3,
        embedding_dim=16,
        generator_dim=(32, 32),
        discriminator_dim=(32, 32),
    )
    model.fit(dataset, table_name="customers", seed=fit_seed)
    return model.sample(100, seed=sample_seed)


def test_seed_produces_identical_output(small_dataset, meta):
    """Two independent CTGAN instances trained and sampled with the same seeds must produce bit-identical DataFrames."""
    run1 = _fit_and_sample(small_dataset, meta, fit_seed=42, sample_seed=7)
    run2 = _fit_and_sample(small_dataset, meta, fit_seed=42, sample_seed=7)

    pd.testing.assert_frame_equal(
        run1, run2,
        check_exact=True,
        obj="Seed-identical runs must produce bit-identical synthetic output",
    )


def test_different_seeds_produce_different_output(small_dataset, meta):
    """Two runs with different seeds should produce different DataFrames (probabilistic sanity check)."""
    run_a = _fit_and_sample(small_dataset, meta, fit_seed=42, sample_seed=7)
    run_b = _fit_and_sample(small_dataset, meta, fit_seed=99, sample_seed=7)

    # They might theoretically be equal by chance, but with a continuous column like income
    # this is astronomically unlikely with different training seeds.
    # Use a soft check — warn rather than hard-fail.
    try:
        pd.testing.assert_frame_equal(run_a, run_b, check_exact=True)
        import warnings
        warnings.warn(
            "Different seeds produced identical output — seed parameterization may not be working correctly.",
            UserWarning,
            stacklevel=2,
        )
    except AssertionError:
        pass  # Expected: different seeds produce different output
```

**After writing all three files**, run the tests:
```bash
cd /Users/arnavdadarya/FedEx/SynthoHive && python -m pytest tests/test_e2e_single_table.py tests/test_serialization.py tests/test_seed_regression.py -v --tb=short 2>&1 | tail -40
```

If any test fails, read the failure output carefully and fix the test or the underlying implementation. Common issues to watch for:
1. CTGAN constructor argument mismatch — read existing test_models.py for the correct args
2. `meta.add_table()` signature — read config.py for the exact API
3. `model.sample()` might not return `id` column — adjust expected_cols accordingly
4. Fixture conflicts with existing conftest.py — check and use conftest fixtures if they exist
  </action>
  <verify>
```bash
python -m pytest /Users/arnavdadarya/FedEx/SynthoHive/tests/test_e2e_single_table.py /Users/arnavdadarya/FedEx/SynthoHive/tests/test_serialization.py /Users/arnavdadarya/FedEx/SynthoHive/tests/test_seed_regression.py -v --tb=short 2>&1 | tail -50
```

All three test files must show `PASSED` for every test function. No `ERROR` or `FAILED` results.

Also run full test suite to confirm no regressions:
```bash
python -m pytest /Users/arnavdadarya/FedEx/SynthoHive/tests/ -x -q --tb=short 2>&1 | tail -20
```
  </verify>
  <done>
- tests/test_e2e_single_table.py: 2 tests PASS
- tests/test_serialization.py: 4 tests PASS (round-trip, overwrite protection, overwrite=True, missing path)
- tests/test_seed_regression.py: 2 tests PASS (identical seeds, different seeds)
- Full test suite: no new failures introduced by Phase 1 changes
  </done>
</task>

</tasks>

<verification>
1. `grep -n "_SAFE_IDENTIFIER" syntho_hive/interface/synthesizer.py` → at least 2 matches (definition + usage)
2. `grep -n "SchemaError" syntho_hive/interface/synthesizer.py | grep "save_to_hive\|SAFE"` → confirms raise is in save_to_hive()
3. `python -m pytest tests/test_e2e_single_table.py tests/test_serialization.py tests/test_seed_regression.py -v` → all PASSED
4. `python -m pytest tests/ -x -q` → no new failures from Phase 1 changes
</verification>

<success_criteria>
- save_to_hive() validates database and table names with `^[a-zA-Z0-9_]+$` before any SQL
- Invalid names raise SchemaError; valid names proceed as before
- TEST-01 (test_e2e_single_table.py): single-table fit/sample test passes
- TEST-03 (test_serialization.py): round-trip test + 3 guard tests all pass
- TEST-05 (test_seed_regression.py): bit-identical seed test passes
- Full test suite has no new failures
- Phase 1 is complete: all 4 plans implemented and all 10 requirements addressed
</success_criteria>

<output>
After completion, create `.planning/phases/01-core-reliability/01-04-SUMMARY.md`
</output>
