---
phase: 01-core-reliability
plan: "03"
type: execute
wave: 2
depends_on:
  - "01-01"
files_modified:
  - syntho_hive/core/models/ctgan.py
  - syntho_hive/core/data/transformer.py
autonomous: true
requirements:
  - QUAL-04
  - QUAL-05

must_haves:
  truths:
    - "CTGAN.fit(df, table_name='customers', seed=42) succeeds without error and logs 'Training seed: 42' via structlog"
    - "CTGAN.fit() with no seed auto-generates one and logs it at INFO level so the run can be reproduced"
    - "Two CTGAN.fit(seed=42).sample(100, seed=7) calls on the same data return DataFrames that pass pd.testing.assert_frame_equal with check_exact=True"
    - "ClusterBasedNormalizer no longer hardcodes random_state=42 — it accepts a seed parameter from DataTransformer.fit(seed=N)"
    - "CTGAN.sample(enforce_constraints=True) returns valid rows and logs a structlog WARNING listing all violations when constraints are breached; it does not crash"
    - "CTGAN.sample(enforce_constraints=False) (default) skips constraint checking entirely"
  artifacts:
    - path: "syntho_hive/core/models/ctgan.py"
      provides: "seed param in fit() and sample(); _set_seed() helper; enforce_constraints in sample()"
      contains: "_set_seed"
      min_lines: 20
    - path: "syntho_hive/core/data/transformer.py"
      provides: "DataTransformer.fit(seed=N) propagated to ClusterBasedNormalizer"
      contains: "random_state=seed"
  key_links:
    - from: "syntho_hive/core/models/ctgan.py CTGAN.fit()"
      to: "syntho_hive/core/data/transformer.py DataTransformer.fit()"
      via: "self.transformer.fit(data, table_name=table_name, seed=seed)"
      pattern: "transformer\\.fit.*seed"
    - from: "syntho_hive/core/data/transformer.py DataTransformer.fit()"
      to: "ClusterBasedNormalizer"
      via: "BayesianGaussianMixture(random_state=derived_seed_per_column)"
      pattern: "random_state.*seed"
    - from: "syntho_hive/core/models/ctgan.py CTGAN.sample()"
      to: "syntho_hive/exceptions.py ConstraintViolationError"
      via: "log.warning('constraint_violations_detected', ...) and return valid rows"
      pattern: "constraint_violations"
---

<objective>
Add deterministic seed control to CTGAN.fit() and CTGAN.sample(), propagate the seed to DataTransformer's BayesianGMM, and implement opt-in constraint violation checking that warns and returns only valid rows.

Purpose: QUAL-05 (reproducibility) is required for data engineers to trust that synthetic datasets can be reproduced for audits and debugging. QUAL-04 (constraint violations) ensures numeric constraints raise actionable errors rather than silently producing out-of-range data.
Output: Modified ctgan.py with _set_seed() helper, seed params in fit/sample, enforce_constraints param. Modified transformer.py with seed propagated to ClusterBasedNormalizer.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-core-reliability/01-CONTEXT.md
@.planning/phases/01-core-reliability/01-RESEARCH.md
@.planning/phases/01-core-reliability/01-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add seed parameter to CTGAN.fit() and propagate to DataTransformer</name>
  <files>
    syntho_hive/core/models/ctgan.py
    syntho_hive/core/data/transformer.py
  </files>
  <action>
**Read both files completely first** to understand current fit() signatures and how DataTransformer.fit() and ClusterBasedNormalizer interact.

**Step 1 — Add `_set_seed()` helper to ctgan.py.**

Add at module level (before the CTGAN class, after imports):

```python
def _set_seed(seed: int) -> None:
    """
    Set all RNG seeds for deterministic behavior.

    Covers PyTorch, NumPy, and Python's random module. Spark code paths are
    explicitly excluded — Spark's distributed shuffle is inherently
    non-deterministic and cannot be seeded via this function.
    """
    import random
    import numpy as np
    import torch
    torch.manual_seed(seed)
    np.random.seed(seed)
    random.seed(seed)
    # CuDNN determinism (no-op on CPU, required for GPU reproducibility)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
```

**Step 2 — Add `seed` parameter to CTGAN.fit().**

Modify the existing `fit()` method signature to accept `seed: int | None = None`. At the top of the method body (before any other logic), add:

```python
import random as _random

if seed is None:
    seed = _random.randint(0, 2**31 - 1)
    log.info("training_seed", seed=seed,
             message="No seed provided — auto-generated. Log this value to reproduce this run.")
else:
    log.info("training_seed", seed=seed)

_set_seed(seed)
```

Then pass `seed` to the DataTransformer fit call:
```python
self.transformer.fit(data, table_name=table_name, seed=seed)
```
(Confirm the exact argument names for the transformer.fit() call in the existing code — adapt accordingly.)

**Step 3 — Add `seed` parameter to CTGAN.sample().**

Modify `sample()` to accept `seed: int | None = None`. At the top of the method body, add:

```python
if seed is not None:
    _set_seed(seed)
```

No auto-generation for sample seed — only apply if provided, per CONTEXT.md decision (separate seeds for fit and sample).

**Step 4 — Propagate seed to DataTransformer.fit() in transformer.py.**

Read `DataTransformer.fit()` to understand its current signature. Add `seed: int | None = None` as a parameter. Find where `ClusterBasedNormalizer` is instantiated (it constructs `BayesianGaussianMixture(random_state=42)` — this hardcoded 42 must be parameterized).

Replace each `BayesianGaussianMixture(random_state=42, ...)` with:
```python
# Derive per-column deterministic seed from the parent seed to avoid
# correlated RNG sequences across columns when all columns share one seed.
col_seed = (seed + abs(hash(col_name)) % 100_000) if seed is not None else 42
BayesianGaussianMixture(random_state=col_seed, ...)
```

Where `col_name` is whatever variable holds the current column name in the fitting loop. If `ClusterBasedNormalizer` is a separate class (not inline in `DataTransformer`), then:
1. Read `ClusterBasedNormalizer` to find where it constructs `BayesianGaussianMixture`
2. Add a `seed` parameter to `ClusterBasedNormalizer.__init__()` or `ClusterBasedNormalizer.fit()`
3. Propagate from `DataTransformer.fit(seed=N)` → `ClusterBasedNormalizer(seed=col_seed)` → `BayesianGaussianMixture(random_state=col_seed)`

The exact propagation path depends on the actual code structure — trace it fully before modifying.
  </action>
  <verify>
```bash
python -c "
import pandas as pd, numpy as np
from syntho_hive.core.models.ctgan import CTGAN, _set_seed
from syntho_hive.interface.config import Metadata

# Verify _set_seed exists
print('_set_seed:', _set_seed)

# Verify seed param in fit signature
import inspect
sig = inspect.signature(CTGAN.fit)
assert 'seed' in sig.parameters, 'fit() missing seed param'

sig2 = inspect.signature(CTGAN.sample)
assert 'seed' in sig2.parameters, 'sample() missing seed param'

# Quick smoke test — fit with seed should not crash
np.random.seed(0)
df = pd.DataFrame({
    'id': range(100),
    'age': np.random.randint(18, 80, 100),
    'city': np.random.choice(['NY','SF'], 100),
})
m = Metadata()
m.add_table('customers', pk='id')
model = CTGAN(m, batch_size=32, epochs=1, embedding_dim=8,
              generator_dim=(16,16), discriminator_dim=(16,16))
model.fit(df, table_name='customers', seed=42)
result = model.sample(20, seed=7)
assert len(result) == 20
print('Seed params smoke test PASSED')
"
```

Also check transformer:
```bash
python -c "
import inspect
from syntho_hive.core.data.transformer import DataTransformer
sig = inspect.signature(DataTransformer.fit)
assert 'seed' in sig.parameters, 'DataTransformer.fit() missing seed param'
print('DataTransformer.fit seed param OK')
"
```
  </verify>
  <done>
- `_set_seed(seed)` function exists in ctgan.py
- CTGAN.fit() accepts seed parameter; logs "training_seed" via structlog
- Auto-generates seed when none provided, logs at INFO
- CTGAN.sample() accepts seed parameter; calls _set_seed() when provided
- DataTransformer.fit() accepts seed parameter; propagates to ClusterBasedNormalizer
- ClusterBasedNormalizer no longer hardcodes random_state=42
  </done>
</task>

<task type="auto">
  <name>Task 2: Add enforce_constraints opt-in to CTGAN.sample() with violation logging</name>
  <files>syntho_hive/core/models/ctgan.py</files>
  <action>
Read the current `sample()` method fully to understand how generated data flows through `inverse_transform()` and what constraint metadata is accessible. Specifically:
1. How does sample() access table metadata (column constraints)?
2. What does `inverse_transform()` return — a DataFrame or numpy array?
3. Does the CTGAN instance have access to `self.metadata` or similar?

**Add `enforce_constraints: bool = False` parameter to sample().**

After `inverse_transform()` produces the result DataFrame, add the constraint checking block (executed only when `enforce_constraints=True`):

```python
if enforce_constraints:
    # Retrieve table constraints from metadata
    # Adapt the metadata access pattern to match the actual CTGAN structure
    # Common patterns: self.metadata.get_table(self.table_name).constraints
    #                  self.metadata.tables[self.table_name].columns
    table_config = None
    if hasattr(self, 'metadata') and self.table_name:
        try:
            table_config = self.metadata.get_table(self.table_name)
        except Exception:
            table_config = None

    if table_config is not None:
        violations = []
        valid_mask = pd.Series([True] * len(result_df), index=result_df.index)

        # Inspect the table_config object to find the constraints attribute
        # (may be table_config.columns, table_config.constraints, or similar)
        # Read the Metadata/config.py to find the correct attribute
        constraints = getattr(table_config, 'constraints',
                     getattr(table_config, 'columns', {}))

        for col_name, constraint in constraints.items():
            if col_name not in result_df.columns:
                continue
            col_data = result_df[col_name]

            # Check min constraint
            min_val = getattr(constraint, 'min', None)
            if min_val is not None:
                bad = col_data < min_val
                if bad.any():
                    observed = col_data[bad].min()
                    violations.append(
                        f"{col_name}: got {observed:.4g} (min={min_val})"
                    )
                    valid_mask &= ~bad

            # Check max constraint
            max_val = getattr(constraint, 'max', None)
            if max_val is not None:
                bad = col_data > max_val
                if bad.any():
                    observed = col_data[bad].max()
                    violations.append(
                        f"{col_name}: got {observed:.4g} (max={max_val})"
                    )
                    valid_mask &= ~bad

        if violations:
            summary = "; ".join(violations)
            log.warning(
                "constraint_violations_detected",
                violation_count=len(violations),
                violations=summary,
                valid_rows=int(valid_mask.sum()),
                total_rows=len(result_df),
                action="returning valid rows only",
            )
            # Per CONTEXT.md decision: return valid rows, warn about violations
            # (partial data returned; engineer decides if violation rate is acceptable)
            result_df = result_df[valid_mask].reset_index(drop=True)
```

**Critical:** Read `syntho_hive/interface/config.py` to understand the Metadata/table config structure and find the correct attribute path to column constraints. The implementation must use the actual attribute names from the config objects, not assumed ones.

If no constraint configuration exists on the table config at all (i.e., the Metadata object doesn't currently support column-level min/max constraints), add a comment in the code explaining this and ensure enforce_constraints=True is a no-op when no constraints are defined (rather than raising an error). Do NOT add a new constraint schema to config.py in this plan — that would be out of scope.
  </action>
  <verify>
```bash
python -c "
import inspect
from syntho_hive.core.models.ctgan import CTGAN
sig = inspect.signature(CTGAN.sample)
assert 'enforce_constraints' in sig.parameters, 'sample() missing enforce_constraints param'
default = sig.parameters['enforce_constraints'].default
assert default == False, f'enforce_constraints default should be False, got {default}'
print('enforce_constraints param OK, default=False')
"
```

Verify no crash when enforce_constraints=True:
```bash
python -c "
import pandas as pd, numpy as np
from syntho_hive.core.models.ctgan import CTGAN
from syntho_hive.interface.config import Metadata

np.random.seed(0)
df = pd.DataFrame({
    'id': range(100),
    'age': np.random.randint(18, 80, 100),
    'city': np.random.choice(['NY','SF'], 100),
})
m = Metadata()
m.add_table('customers', pk='id')
model = CTGAN(m, batch_size=32, epochs=1, embedding_dim=8,
              generator_dim=(16,16), discriminator_dim=(16,16))
model.fit(df, table_name='customers', seed=42)
result = model.sample(20, enforce_constraints=True, seed=7)
assert result is not None, 'sample() returned None'
print('enforce_constraints=True does not crash, returned', len(result), 'rows')
"
```
  </verify>
  <done>
- CTGAN.sample() accepts enforce_constraints=False (default) and enforce_constraints=True
- With enforce_constraints=True: scans generated batch for constraint violations, logs structlog WARNING with violation summary, returns only valid rows
- With enforce_constraints=False: skips all constraint checking (existing behavior unchanged)
- sample() does not crash when enforce_constraints=True and no constraints are configured
  </done>
</task>

</tasks>

<verification>
1. `python -c "from syntho_hive.core.models.ctgan import _set_seed; print('OK')"` → OK
2. `inspect.signature(CTGAN.fit)` includes `seed` param
3. `inspect.signature(CTGAN.sample)` includes `seed` and `enforce_constraints` params
4. `inspect.signature(DataTransformer.fit)` includes `seed` param
5. `grep -n "random_state=42" syntho_hive/core/data/transformer.py` → zero results (hardcoded seed gone)
6. `grep -n "random_state=seed" syntho_hive/core/data/transformer.py` → at least one result (parameterized)
</verification>

<success_criteria>
- _set_seed(seed) helper exists in ctgan.py, sets torch + numpy + random + cudnn determinism
- CTGAN.fit() accepts seed=None|int; auto-generates and logs when None; calls _set_seed()
- CTGAN.sample() accepts seed=None|int; calls _set_seed() when provided
- DataTransformer.fit() accepts seed param; no hardcoded random_state=42 in ClusterBasedNormalizer
- CTGAN.sample() accepts enforce_constraints=False (default); when True, warns and returns valid rows
- Pre-existing tests still pass
</success_criteria>

<output>
After completion, create `.planning/phases/01-core-reliability/01-03-SUMMARY.md`
</output>
