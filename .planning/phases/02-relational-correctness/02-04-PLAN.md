---
phase: 02-relational-correctness
plan: "04"
type: tdd
wave: 3
depends_on:
  - "02-01"
  - "02-02"
  - "02-03"
files_modified:
  - tests/test_relational.py
autonomous: true
requirements:
  - REL-05
  - TEST-02

must_haves:
  truths:
    - "3-table FK chain (users → orders → items) produces zero orphaned references after generation"
    - "4-table FK chain (users → orders → items → reviews) produces zero orphaned references — cascade integrity"
    - "SchemaValidationError is raised when child FK column type is int but parent PK is string (and vice versa)"
    - "SchemaValidationError is raised when child table is missing the FK column entirely"
    - "Empirical cardinality distribution: mean child count in generated data is within 20% of training data mean"
    - "All TEST-02 tests run without a real Spark session (uses MockSparkDF pattern)"
  artifacts:
    - path: "tests/test_relational.py"
      provides: "TEST-02: FK chain zero-orphan, cardinality accuracy, SchemaValidationError tests"
      contains: "TestFKChainIntegrity"
  key_links:
    - from: "tests/test_relational.py"
      to: "syntho_hive/relational/orchestrator.py"
      via: "MockSparkDF + mock io.read_dataset / io.write_pandas"
      pattern: "MockSparkDF"
    - from: "tests/test_relational.py"
      to: "syntho_hive/exceptions.py"
      via: "pytest.raises(SchemaValidationError)"
      pattern: "SchemaValidationError"
---

<objective>
Write TEST-02: the end-to-end relational correctness test suite validating that Plans 01-03 work together to produce FK-correct multi-table output.

Purpose: This is the observable proof that REL-05 is satisfied — generated tables join with zero orphans. TDD structure: write tests first (RED), confirm they fail against the existing broken behavior, then verify they pass after Plans 01-03 are applied.

Output: TestFKChainIntegrity class in tests/test_relational.py with 5 test methods covering 3-table chain, 4-table chain, FK type mismatch, missing FK column, and cardinality accuracy.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-relational-correctness/02-CONTEXT.md
@.planning/phases/02-relational-correctness/02-RESEARCH.md
@tests/test_relational.py
@syntho_hive/relational/orchestrator.py
@syntho_hive/relational/linkage.py
@syntho_hive/interface/config.py
@syntho_hive/exceptions.py
@.planning/phases/02-relational-correctness/02-01-SUMMARY.md
@.planning/phases/02-relational-correctness/02-02-SUMMARY.md
@.planning/phases/02-relational-correctness/02-03-SUMMARY.md
</context>

<feature>
  <name>TEST-02: FK Chain Integrity and Schema Validation</name>
  <files>tests/test_relational.py, (implementation already in Plans 01-03)</files>
  <behavior>
5 test cases, all in class TestFKChainIntegrity(unittest.TestCase):

1. test_3_table_chain_zero_orphans:
   Schema: users (pk=id) → orders (fk=user_id→users.id) → items (fk=order_id→orders.id)
   Input: 20 users, ~60 orders (~3 per user), ~180 items (~3 per order) [np.random.seed(42)]
   Action: fit StagedOrchestrator on this data, then generate with output_path_base set to temp dir
   Assert: generated_orders.user_id values are all in generated_users.id (zero orphans)
   Assert: generated_items.order_id values are all in generated_orders.id (zero orphans)

2. test_4_table_chain_zero_orphans:
   Schema: users → orders → items → reviews (fk=item_id→items.id)
   Input: 10 users, ~30 orders, ~90 items, ~270 reviews [np.random.seed(0)]
   Action: fit + generate with output_path_base set to temp dir
   Assert: zero orphans at each join level

3. test_fk_type_mismatch_raises_schema_validation_error:
   Schema: users (pk=id, integer) → orders (fk=user_id, string)
   Action: meta.validate_schema(real_data={'users': parent_df, 'orders': child_df})
   Assert: pytest.raises(SchemaValidationError)
   Assert: 'mismatch' in str(e).lower() OR 'type' in str(e).lower()

4. test_fk_missing_column_raises_schema_validation_error:
   Schema: users (pk=id) → orders (fk=user_id) — but orders DataFrame has no user_id column
   Action: meta.validate_schema(real_data={'users': parent_df, 'orders': child_df})
   Assert: pytest.raises(SchemaValidationError)
   Assert: 'missing' in str(e).lower() OR 'user_id' in str(e).lower()

5. test_cardinality_within_tolerance:
   Schema: users (pk=id) → orders (fk=user_id)
   Training: 50 users, each with exactly 3 orders (controlled distribution; mean=3.0)
   Action: fit LinkageModel(method='empirical') + sample_counts on 50-parent context
   Assert: abs(generated_mean - 3.0) / 3.0 < 0.20 (within 20% relative tolerance)

Cases:
- 3-table fit+generate → zero orphans on user_id and order_id joins
- 4-table fit+generate → zero orphans at all 3 join levels
- int_pk / str_fk → SchemaValidationError raised
- missing FK column → SchemaValidationError raised
- empirical cardinality → mean child count within 20% of training distribution
  </behavior>
  <implementation>
Use MockSparkDF pattern from existing test_relational.py. Do NOT require a real Spark session.

For FK chain tests (test 1 and test 2), use this approach:
1. Create small pandas DataFrames for each table with controlled data (np.random.seed for reproducibility)
2. Mock orchestrator.io.read_dataset to return MockSparkDF(df) for the right table
3. Use a temp directory (tempfile.mkdtemp()) for output_path_base
4. Mock orchestrator.io.write_pandas to actually write CSV to the temp dir so the orchestrator's disk-read path for child tables can read parent data back
5. After generation, read generated output from temp dir and join to verify zero orphans

IMPORTANT: The MockSparkDF and I/O mock setup must exactly follow the existing pattern in test_relational.py. Read the file first to understand the current mock infrastructure before writing new tests.

For the cardinality test (test 5), test LinkageModel directly — no need to run the full orchestrator. Just fit + sample_counts and check the mean.

For schema validation tests (tests 3 and 4), call meta.validate_schema(real_data=...) directly — no orchestrator needed.

FK chain generation approach for tests 1 and 2:
- Train a real (fast) CTGAN with batch_size=20, epochs=2 on small data to produce valid generator state
- Then call orchestrator.generate() with the mocked I/O and temp output_path_base
- FK columns should be excluded from CTGAN transformation (DataTransformer._excluded_columns) and preserved as-is during generation — verify this is still true after Plans 01-03
- After generation, read CSVs from temp dir, join on FK keys, assert zero orphans via pd.merge(..., how='inner') length equals outer join length

Teardown: Use shutil.rmtree(temp_dir) in tearDown() to clean up temp files.
  </implementation>
</feature>

<tasks>

<task type="auto">
  <name>Task 1: Write and verify TEST-02 (TestFKChainIntegrity)</name>
  <files>tests/test_relational.py</files>
  <action>
Read tests/test_relational.py fully to understand the existing MockSparkDF pattern and test structure.

Add the TestFKChainIntegrity class to tests/test_relational.py. Do NOT replace or modify any existing tests — only append the new class.

Follow this TDD cycle:

**RED phase:** Write all 5 test methods before checking if they pass. The schema validation tests (3 and 4) should already pass since Plans 01-03 are complete by this point. The FK chain tests (1 and 2) verify the full integration.

**Structure the class as follows:**

```python
import os
import shutil
import tempfile
import unittest
import numpy as np
import pandas as pd
import pytest
from unittest.mock import MagicMock

from syntho_hive.interface.config import Metadata, TableConfig
from syntho_hive.exceptions import SchemaValidationError
from syntho_hive.relational.linkage import LinkageModel


class TestFKChainIntegrity(unittest.TestCase):
    """TEST-02: Multi-table FK chain — zero orphans, cardinality accuracy, schema validation."""

    def setUp(self):
        self.temp_dir = tempfile.mkdtemp()

    def tearDown(self):
        shutil.rmtree(self.temp_dir, ignore_errors=True)
```

**test_3_table_chain_zero_orphans:**
Build metadata for users → orders → items. Create small DataFrames (np.random.seed(42)). Wire MockSparkDF mocks. Run a fast fit (epochs=2, batch_size=20). Run generate with output_path_base=self.temp_dir. Load CSVs from temp dir. Assert zero orphans using:
```python
# Zero orphan check: inner join should have same rows as child table
merged = generated_orders.merge(generated_users, left_on='user_id', right_on='id', how='inner')
assert len(merged) == len(generated_orders), f"Orphaned orders: {len(generated_orders) - len(merged)}"
```
Apply same check for items → orders join.

**test_4_table_chain_zero_orphans:**
Same pattern, 4-table chain: users → orders → items → reviews. Use np.random.seed(0). Check all 3 join levels.

**test_fk_type_mismatch_raises_schema_validation_error:**
```python
meta = Metadata()
meta.add_table('users', 'id')
meta.add_table('orders', 'order_id', fk={'user_id': 'users.id'})
parent_df = pd.DataFrame({'id': [1, 2, 3]})  # int
child_df = pd.DataFrame({'order_id': [1, 2], 'user_id': ['1', '2']})  # str FK
with pytest.raises(SchemaValidationError) as exc_info:
    meta.validate_schema(real_data={'users': parent_df, 'orders': child_df})
assert 'mismatch' in str(exc_info.value).lower() or 'type' in str(exc_info.value).lower()
```

**test_fk_missing_column_raises_schema_validation_error:**
```python
meta = Metadata()
meta.add_table('users', 'id')
meta.add_table('orders', 'order_id', fk={'user_id': 'users.id'})
parent_df = pd.DataFrame({'id': [1, 2]})
child_df = pd.DataFrame({'order_id': [1, 2]})  # no user_id column
with pytest.raises(SchemaValidationError) as exc_info:
    meta.validate_schema(real_data={'users': parent_df, 'orders': child_df})
assert 'missing' in str(exc_info.value).lower() or 'user_id' in str(exc_info.value).lower()
```

**test_cardinality_within_tolerance:**
```python
np.random.seed(7)
# 50 parents, each with exactly 3 children → observed_counts all = 3
parent_df = pd.DataFrame({'id': range(50)})
child_df = pd.DataFrame({
    'parent_id': np.repeat(range(50), 3),
    'id': range(150)
})
model = LinkageModel(method='empirical')
model.fit(parent_df, child_df, fk_col='parent_id', pk_col='id')
# Generate counts for 50 parents — mean should be near 3.0
sampled = model.sample_counts(parent_df)
sampled_mean = float(np.mean(sampled))
rel_error = abs(sampled_mean - 3.0) / 3.0
assert rel_error < 0.20, f"Cardinality drift: {sampled_mean:.2f} vs expected 3.0 (rel error {rel_error:.2%})"
```

For the FK chain integration tests, if the full orchestrator fit + generate is too slow or has infrastructure issues with mock I/O, write the test to directly exercise the sub-components (fit LinkageModel + validate FK columns are preserved in CTGAN output) rather than a full orchestrator round-trip. Use your judgment on which approach gives the most reliable zero-orphan verification with the mock infrastructure.
  </action>
  <verify>
**Run the new test class specifically:**
```bash
cd /Users/arnavdadarya/FedEx/SynthoHive && python -m pytest tests/test_relational.py::TestFKChainIntegrity -v --tb=short 2>&1
```

Expected: All 5 test methods pass.

**Run full test suite:**
```bash
cd /Users/arnavdadarya/FedEx/SynthoHive && python -m pytest tests/ -x --tb=short -q 2>&1 | tail -25
```

Expected: All tests pass including existing test_relational.py tests.
  </verify>
  <done>
- TestFKChainIntegrity class appended to tests/test_relational.py with 5 test methods
- test_3_table_chain_zero_orphans: passes with zero orphan assertion
- test_4_table_chain_zero_orphans: passes with zero orphan assertions at all join levels
- test_fk_type_mismatch_raises_schema_validation_error: SchemaValidationError raised with type mismatch message
- test_fk_missing_column_raises_schema_validation_error: SchemaValidationError raised with missing column message
- test_cardinality_within_tolerance: empirical cardinality within 20% tolerance
- All tests run without a real Spark session
- Full test suite passes with no regressions
  </done>
</task>

</tasks>

<verification>
```bash
# Run TEST-02 specifically
cd /Users/arnavdadarya/FedEx/SynthoHive && python -m pytest tests/test_relational.py::TestFKChainIntegrity -v 2>&1

# Run full suite
cd /Users/arnavdadarya/FedEx/SynthoHive && python -m pytest tests/ --tb=short -q 2>&1 | tail -25
```

Phase 2 success criteria check — these must all be TRUE:
1. Join users + orders on user_id: zero orphans (inner == outer count)
2. Join orders + items on order_id: zero orphans
3. validate_schema(int_pk, str_fk) → SchemaValidationError raised
4. validate_schema(missing_fk_col) → SchemaValidationError raised
5. Empirical cardinality mean within 20% tolerance
6. No Spark session required for any test
</verification>

<success_criteria>
- TestFKChainIntegrity has 5 passing test methods
- FK join zero-orphan verification passes for 3-table and 4-table chains
- SchemaValidationError raised correctly for type mismatch and missing column cases
- Cardinality accuracy within 20% relative tolerance
- All tests Spark-free (MockSparkDF pattern)
- Full pytest suite passes with no regressions introduced by Plans 01-04
</success_criteria>

<output>
After completion, create `.planning/phases/02-relational-correctness/02-04-SUMMARY.md`
</output>
