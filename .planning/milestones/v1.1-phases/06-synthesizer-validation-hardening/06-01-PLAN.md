---
phase: 06-synthesizer-validation-hardening
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - syntho_hive/interface/synthesizer.py
  - syntho_hive/tests/test_interface.py
autonomous: true
requirements:
  - REL-03
  - MODEL-02

must_haves:
  truths:
    - "Synthesizer(model=InvalidClass, spark_session=None) raises TypeError at __init__ time — not deferred to fit()"
    - "Synthesizer.fit(data=dfs, validate=True) raises SchemaValidationError when FK columns have type mismatches"
    - "pytest syntho_hive/tests/test_interface.py exits with both new tests passing and no regressions to pre-existing passing tests"
    - "Synthesizer(model=CTGAN) still constructs without error (no false-positive guard trips)"
  artifacts:
    - path: "syntho_hive/interface/synthesizer.py"
      provides: "TD-04 issubclass guard in __init__; TD-01 real_data passthrough in fit()"
      contains: "isinstance(model, type) and issubclass(model, ConditionalGenerativeModel)"
    - path: "syntho_hive/tests/test_interface.py"
      provides: "test_synthesizer_rejects_invalid_model_cls_without_spark and test_synthesizer_fit_validate_catches_fk_type_mismatch"
      contains: "test_synthesizer_rejects_invalid_model_cls_without_spark"
  key_links:
    - from: "syntho_hive/interface/synthesizer.py:__init__"
      to: "ConditionalGenerativeModel (base.py)"
      via: "isinstance + issubclass guard before Spark check"
      pattern: "isinstance\\(model, type\\) and issubclass\\(model, ConditionalGenerativeModel\\)"
    - from: "syntho_hive/interface/synthesizer.py:fit"
      to: "Metadata.validate_schema (config.py)"
      via: "real_data=data when data is a dict of DataFrames"
      pattern: "validate_schema\\(real_data=data\\)"
---

<objective>
Fix two partial-wiring gaps in the Synthesizer public facade catalogued as TD-01 and TD-04 in the v1.1 milestone audit, and add regression tests for each fix.

Purpose: Two E2E flows in the Synthesizer are silently broken. TD-04: invalid model_cls passes through `__init__` without error when spark_session=None — the guard only fires inside StagedOrchestrator, which is never constructed in the no-Spark path. TD-01: `fit(validate=True)` calls `validate_schema()` with no arguments, skipping all data-level FK type mismatch detection silently. Both fixes are surgical one-file changes with defined patterns from Phase 03 and Phase 02 respectively.

Output:
- `syntho_hive/interface/synthesizer.py` — two targeted edits (guard block in `__init__`, real_data detection in `fit()`)
- `syntho_hive/tests/test_interface.py` — two new test functions covering TD-04 and TD-01 fixes
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-synthesizer-validation-hardening/06-RESEARCH.md
@.planning/v1.1-MILESTONE-AUDIT.md
@syntho_hive/interface/synthesizer.py
@syntho_hive/tests/test_interface.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Fix TD-04 issubclass guard and TD-01 real_data passthrough in synthesizer.py</name>
  <files>syntho_hive/interface/synthesizer.py</files>
  <action>
Make two targeted edits to `syntho_hive/interface/synthesizer.py`. Do NOT rewrite the file — apply surgical changes only.

**Edit 1 — TD-04: Add issubclass guard in Synthesizer.__init__() (lines 59–70 region)**

After the docstring closes and before `self.metadata = metadata` (current line 60), insert this guard block:

```python
if not (isinstance(model, type) and issubclass(model, ConditionalGenerativeModel)):
    raise TypeError(
        f"model_cls must be a subclass of ConditionalGenerativeModel, "
        f"got {model!r}. Implement fit(), sample(), save(), load() "
        f"and subclass ConditionalGenerativeModel."
    )
```

This mirrors the existing guard in `syntho_hive/relational/orchestrator.py:81–86` exactly, with the addition of `isinstance(model, type)` to safely handle non-class inputs (e.g., an instance passed instead of a class — raw `issubclass()` would crash on non-class args).

The guard fires BEFORE `self.spark = spark_session` (line 62) and BEFORE the `if self.spark:` block (line 67), so it runs unconditionally regardless of Spark session presence.

The `ConditionalGenerativeModel` import is already present at line 14: `from syntho_hive.core.models.base import ConditionalGenerativeModel`. No new imports needed.

**Edit 2 — TD-01: Pass real_data to validate_schema() in fit() (lines 104–105 region)**

Current code at lines 104–105:
```python
if validate:
    self.metadata.validate_schema()
```

Replace with:
```python
if validate:
    if isinstance(data, dict) and data and isinstance(next(iter(data.values())), pd.DataFrame):
        # User passed actual DataFrames — data-level FK type checks are possible
        self.metadata.validate_schema(real_data=data)
    else:
        # String (DB name) or dict of path strings — structural checks only
        self.metadata.validate_schema()
```

IMPORTANT: This validate block is currently at lines 104–105, which is INSIDE the `try:` block (line 97) and AFTER the orchestrator check (line 98–99). The validate block must be moved to BEFORE the `if not self.orchestrator:` check (line 98), because:
1. `validate_schema()` operates on in-memory metadata — no Spark required
2. This lets `fit(data=dfs, validate=True)` surface FK type mismatches even without a Spark session
3. The test `test_synthesizer_fit_validate_catches_fk_type_mismatch` passes `spark_session=None`, so validation must run before the Spark guard fails

Resulting `fit()` method try-block opening should be:
```python
try:
    if validate:
        if isinstance(data, dict) and data and isinstance(next(iter(data.values())), pd.DataFrame):
            self.metadata.validate_schema(real_data=data)
        else:
            self.metadata.validate_schema()

    if not self.orchestrator:
        raise ValueError("SparkSession required for fit()")

    if sample_size <= 0:
        raise ValueError("sample_size must be positive")
    # ... rest unchanged
```

`SchemaValidationError` is a `SynthoHiveError` subclass (SchemaValidationError → SchemaError → SynthoHiveError). The existing `except SynthoHiveError: raise` at line 122 re-raises it unchanged — no exception wrapping changes needed.

`pd` (pandas) is already imported at line 2. No new imports needed.
  </action>
  <verify>
Run: `python -c "from syntho_hive.interface.synthesizer import Synthesizer; print('import OK')"` — must print `import OK` with no errors.

Run: `python -c "
from syntho_hive.interface.synthesizer import Synthesizer
from syntho_hive.interface.config import Metadata, PrivacyConfig

class NotAModel:
    pass

meta = Metadata()
meta.add_table('users', 'user_id')
try:
    Synthesizer(meta, PrivacyConfig(), spark_session=None, model=NotAModel)
    print('FAIL: no error raised')
except TypeError as e:
    print(f'PASS TD-04: {e}')
"` — must print `PASS TD-04: ...`.
  </verify>
  <done>
- `synthesizer.py` imports cleanly (no syntax errors)
- `Synthesizer(model=NotAModel, spark_session=None)` raises `TypeError` with message matching "ConditionalGenerativeModel"
- `Synthesizer(model=CTGAN, spark_session=None)` constructs without error (no false positive)
- `fit()` validate block appears before the orchestrator check in the method body
  </done>
</task>

<task type="auto">
  <name>Task 2: Add TD-04 and TD-01 regression tests to test_interface.py</name>
  <files>syntho_hive/tests/test_interface.py</files>
  <action>
Append two new test functions to the END of `syntho_hive/tests/test_interface.py`, after the existing `test_issubclass_guard_rejects_invalid_model_cls` function (currently the last test, line 200–212).

Both tests use the existing `metadata` and `privacy_config` fixtures already defined in the file (lines 19–27). `pd` (pandas) is already imported at line 100. `SchemaValidationError` is already imported at line 6.

**Test 1 — TD-04 fix verification:**

```python
def test_synthesizer_rejects_invalid_model_cls_without_spark(metadata, privacy_config):
    """TD-04 fix: Synthesizer raises TypeError at __init__ even when spark_session=None.

    Before the fix, invalid model_cls was silently accepted when spark_session=None
    because the issubclass guard lived only inside StagedOrchestrator.__init__(),
    which is never called when no Spark session is provided.
    """
    class NotAModel:
        pass

    with pytest.raises(TypeError, match="ConditionalGenerativeModel"):
        Synthesizer(metadata, privacy_config, spark_session=None, model=NotAModel)
```

**Test 2 — TD-01 fix verification:**

```python
def test_synthesizer_fit_validate_catches_fk_type_mismatch(metadata, privacy_config):
    """TD-01 fix: fit(validate=True, data=DataFrames) raises SchemaValidationError on FK mismatch.

    The metadata fixture defines users.user_id (PK) and orders.user_id (FK).
    Passing users_df with int user_id and orders_df with str user_id creates a
    dtype mismatch that validate_schema(real_data=dfs) detects.

    Before the fix, validate_schema() was called without real_data, so data-level
    FK type checks were silently skipped through the Synthesizer facade.
    """
    users_df = pd.DataFrame({"user_id": [1, 2, 3], "name": ["alice", "bob", "carol"]})
    orders_df = pd.DataFrame({"order_id": [10, 11], "user_id": ["1", "2"]})  # str FK — mismatch

    syn = Synthesizer(metadata, privacy_config, spark_session=None)
    with pytest.raises(SchemaValidationError):
        syn.fit(data={"users": users_df, "orders": orders_df}, validate=True)
```

Note on test design: `metadata` fixture has `users.user_id` (int64 from `range`) vs `orders.user_id` (object/str from `["1", "2"]`). The `_dtypes_compatible()` function in `config.py` returns `False` for int64 vs object — this is a detectable mismatch. `validate_schema(real_data=dfs)` collects this error and raises `SchemaValidationError`.

Note: `syn.fit(data=dfs, validate=True)` with `spark_session=None` will run validation first (per the Task 1 reordering), raise `SchemaValidationError` from inside the `try:` block, hit `except SynthoHiveError: raise` and propagate unchanged. The test correctly expects `SchemaValidationError` (not `TrainingError`).
  </action>
  <verify>
Run: `python -m pytest syntho_hive/tests/test_interface.py -v --tb=short 2>&1 | tail -30`

Expected output includes:
- `test_synthesizer_rejects_invalid_model_cls_without_spark PASSED`
- `test_synthesizer_fit_validate_catches_fk_type_mismatch PASSED`
- All previously-passing tests still PASSED
- Zero new failures introduced
  </verify>
  <done>
- Both new test functions are present at end of `test_interface.py`
- `pytest syntho_hive/tests/test_interface.py -v` shows both new tests PASSED
- All tests that passed before this plan still pass (no regressions)
- `test_synthesizer_rejects_invalid_model_cls_without_spark` — asserts `TypeError` at `__init__` without Spark
- `test_synthesizer_fit_validate_catches_fk_type_mismatch` — asserts `SchemaValidationError` from `fit(validate=True, data=dfs)` with type-mismatched FK
  </done>
</task>

</tasks>

<verification>
Run the full test file to confirm both fixes and no regressions:

```bash
python -m pytest syntho_hive/tests/test_interface.py -v --tb=short
```

Also run the broader Phase 03 test suite to confirm no regressions in model pluggability:

```bash
python -m pytest syntho_hive/tests/ -v --tb=short -k "not test_synthesizer_fit_requires_spark and not test_synthesizer_sample_requires_spark and not test_synthesizer_fit_call and not test_synthesizer_sample_call"
```

(The 4 pre-existing failures in test_interface.py — TD-02 — are out of scope for Phase 6. They are excluded above to isolate Phase 6 verification from Phase 7 work.)

Spot-check the guard fires correctly:
```bash
python -c "
from syntho_hive.interface.synthesizer import Synthesizer
from syntho_hive.interface.config import Metadata, PrivacyConfig
from syntho_hive.core.models.ctgan import CTGAN

meta = Metadata()
meta.add_table('t', 'id')

# Must succeed (valid class)
syn = Synthesizer(meta, PrivacyConfig(), spark_session=None, model=CTGAN)
print('PASS: CTGAN accepted')

# Must succeed (valid class, no spark)
syn2 = Synthesizer(meta, PrivacyConfig(), spark_session=None)
print('PASS: default CTGAN accepted')

# Must fail (not a class)
try:
    Synthesizer(meta, PrivacyConfig(), spark_session=None, model=CTGAN())
    print('FAIL: instance accepted as model')
except TypeError as e:
    print(f'PASS: instance rejected: {e}')

# Must fail (class not subclassing ABC)
class NotAModel: pass
try:
    Synthesizer(meta, PrivacyConfig(), spark_session=None, model=NotAModel)
    print('FAIL: NotAModel accepted')
except TypeError as e:
    print(f'PASS: NotAModel rejected: {e}')
"
```
</verification>

<success_criteria>
Phase 6 is complete when:
1. `Synthesizer.__init__()` raises `TypeError` with message matching "ConditionalGenerativeModel" for any model argument that is not a class subclassing `ConditionalGenerativeModel` — regardless of whether `spark_session` is provided
2. `Synthesizer.fit(data=dfs, validate=True)` where `dfs` is a `Dict[str, pd.DataFrame]` calls `validate_schema(real_data=dfs)` and raises `SchemaValidationError` when FK dtype mismatches exist
3. `pytest syntho_hive/tests/test_interface.py` shows both `test_synthesizer_rejects_invalid_model_cls_without_spark` and `test_synthesizer_fit_validate_catches_fk_type_mismatch` as PASSED
4. All tests that were passing before this phase continue to pass
5. REL-03 and MODEL-02 E2E flows from the v1.1 audit are no longer "Broken" — both flows complete without the identified break points
</success_criteria>

<output>
After completion, create `.planning/phases/06-synthesizer-validation-hardening/06-01-SUMMARY.md` using the summary template at `@./.claude/get-shit-done/templates/summary.md`.
</output>
