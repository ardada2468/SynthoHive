---
phase: 02-relational-correctness
plan: "01"
type: execute
wave: 1
depends_on: []
files_modified:
  - syntho_hive/exceptions.py
  - syntho_hive/interface/config.py
autonomous: true
requirements:
  - REL-03

must_haves:
  truths:
    - "validate_schema() raises SchemaValidationError listing ALL FK problems — not just the first one"
    - "FK type mismatches (int PK vs string FK) are detected and described with a concrete fix hint"
    - "Missing FK columns in child tables are detected and described in the error message"
    - "SchemaValidationError is a subclass of SchemaError so existing except SchemaError handlers still catch it"
    - "TableConfig has a linkage_method field defaulting to 'empirical' for per-table cardinality config"
  artifacts:
    - path: "syntho_hive/exceptions.py"
      provides: "SchemaValidationError exception class"
      contains: "class SchemaValidationError(SchemaError)"
    - path: "syntho_hive/interface/config.py"
      provides: "Extended validate_schema() with collect-all FK type/column checks and linkage_method field"
      contains: "linkage_method"
  key_links:
    - from: "syntho_hive/interface/config.py"
      to: "syntho_hive/exceptions.py"
      via: "from syntho_hive.exceptions import SchemaValidationError"
      pattern: "SchemaValidationError"
    - from: "syntho_hive/interface/config.py"
      to: "validate_schema(real_data)"
      via: "collect-all errors list then raise once"
      pattern: "errors\\.append"
---

<objective>
Add SchemaValidationError to the exception hierarchy and extend validate_schema() to detect FK type mismatches and missing FK columns at schema validation time — before training begins.

Purpose: Engineers need a single, readable error that lists all schema problems at once so they can fix the entire schema in one pass. Currently validate_schema() only checks table existence; type mismatches and missing columns are silent bugs that produce corrupt joins downstream.

Output: SchemaValidationError class in exceptions.py; extended validate_schema() in config.py that accepts real DataFrames and performs collect-all FK type/column checking; linkage_method field on TableConfig for per-table cardinality method selection.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-relational-correctness/02-CONTEXT.md
@.planning/phases/02-relational-correctness/02-RESEARCH.md
@syntho_hive/exceptions.py
@syntho_hive/interface/config.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add SchemaValidationError to exceptions.py</name>
  <files>syntho_hive/exceptions.py</files>
  <action>
Read syntho_hive/exceptions.py to understand the current exception hierarchy.

Add SchemaValidationError as a subclass of SchemaError (NOT SynthoHiveError directly — subclassing SchemaError preserves the hierarchy so existing `except SchemaError` handlers catch both):

```python
class SchemaValidationError(SchemaError):
    """
    Raised by validate_schema() when FK type mismatches, missing FK columns,
    or invalid FK references are detected. Collects all errors before raising
    so callers see the complete problem list in a single exception.
    """
    pass
```

Place this definition immediately after the SchemaError class definition.

Do NOT change any existing exception classes. Do NOT add __init__ override — the docstring-only subclass is sufficient; the error message is set by the caller via the string argument.
  </action>
  <verify>
Run: `python -c "from syntho_hive.exceptions import SchemaValidationError, SchemaError; e = SchemaValidationError('test'); assert isinstance(e, SchemaError), 'must be subclass of SchemaError'; print('OK')"`

Expected output: `OK`
  </verify>
  <done>SchemaValidationError imports cleanly and isinstance(SchemaValidationError('x'), SchemaError) is True.</done>
</task>

<task type="auto">
  <name>Task 2: Extend validate_schema() and add linkage_method to TableConfig</name>
  <files>syntho_hive/interface/config.py</files>
  <action>
Read syntho_hive/interface/config.py fully. Identify:
- The TableConfig Pydantic model
- The Metadata.validate_schema() method and its current signature
- The existing FK reference checks

Make two changes:

### Change 1: Add linkage_method to TableConfig

Add a new field to TableConfig:
```python
from typing import Literal
linkage_method: Literal["empirical", "negbinom"] = "empirical"
```

Place it alongside existing fields like `fk` and `parent_context_cols`. This is per-table configuration for cardinality distribution method.

### Change 2: Extend validate_schema() with collect-all FK checks

Modify the validate_schema() signature to accept an optional real_data parameter:
```python
def validate_schema(self, real_data: Optional[Dict[str, pd.DataFrame]] = None) -> None:
```

Add imports at the top of config.py if not already present:
- `import numpy as np`
- `from typing import Optional, Dict`
- `import pandas as pd`
- `from syntho_hive.exceptions import SchemaValidationError`

Rewrite (or extend) validate_schema() with the collect-all pattern:

1. Initialize `errors: List[str] = []`
2. For each table_name, table_config in self.tables.items():
   - For each local_col, parent_ref in table_config.fk.items():
     - If "." not in parent_ref: append error "Invalid FK reference '{parent_ref}' in table '{table_name}'." and continue
     - Split into parent_table, parent_col
     - If parent_table not in self.tables: append error "Table '{table_name}' references non-existent parent table '{parent_table}'." and continue
     - If real_data is not None: run type/column checks:
       - If table_name not in real_data or parent_table not in real_data: skip type check (not fatal when data partially provided)
       - If local_col not in child_df.columns: append "FK column '{local_col}' missing from table '{table_name}'. Add column '{local_col}' to child table '{table_name}'."
       - Elif parent_col not in parent_df.columns: append "Parent PK column '{parent_col}' missing from table '{parent_table}'."
       - Else: call _dtypes_compatible(child_dtype, parent_dtype); if not compatible append "FK type mismatch: '{table_name}.{local_col}' is {child_dtype} but '{parent_table}.{parent_col}' is {parent_dtype}. Fix: cast '{table_name}.{local_col}' to {parent_dtype} or cast '{parent_table}.{parent_col}' to {child_dtype}."
3. If errors: raise SchemaValidationError("\n".join(errors))

Add the _dtypes_compatible helper function at module level (not inside the class):

```python
def _dtypes_compatible(dtype_a: str, dtype_b: str) -> bool:
    """Return True if both dtypes belong to the same broad category (integer or string/object)."""
    try:
        kind_a = np.dtype(dtype_a).kind
        kind_b = np.dtype(dtype_b).kind
    except TypeError:
        # pandas extension types (StringDtype, Int64Dtype) — be conservative
        return True
    integer_kinds = {'i', 'u'}
    string_kinds = {'U', 'O', 'S'}
    if kind_a in integer_kinds and kind_b in integer_kinds:
        return True
    if kind_a in string_kinds and kind_b in string_kinds:
        return True
    if kind_a == 'f' and kind_b == 'f':
        return True
    return False
```

IMPORTANT: Get the column dtype string via `str(df[col].dtype)`. Pass that string to _dtypes_compatible.

IMPORTANT: Preserve all existing validate_schema() behavior — the new check is additive. Existing callers that pass no arguments still get the table-existence and FK-format checks.
  </action>
  <verify>
Run the following inline test to confirm all four check types:

```bash
python -c "
import pandas as pd
import numpy as np
from syntho_hive.interface.config import Metadata, TableConfig
from syntho_hive.exceptions import SchemaValidationError, SchemaError

# Test 1: existing table-not-found still works
meta = Metadata()
meta.add_table('orders', 'id', fk={'user_id': 'users.id'})
try:
    meta.validate_schema()
    assert False, 'should have raised'
except SchemaValidationError as e:
    assert isinstance(e, SchemaError)
    print('Test 1 PASS: table not found raises SchemaValidationError (subclass of SchemaError)')

# Test 2: type mismatch detected
meta2 = Metadata()
meta2.add_table('users', 'id')
meta2.add_table('orders', 'order_id', fk={'user_id': 'users.id'})
parent_df = pd.DataFrame({'id': [1, 2, 3]})  # int
child_df = pd.DataFrame({'order_id': [1, 2], 'user_id': ['1', '2']})  # string FK
try:
    meta2.validate_schema(real_data={'users': parent_df, 'orders': child_df})
    assert False, 'should have raised'
except SchemaValidationError as e:
    assert 'type mismatch' in str(e).lower() or 'mismatch' in str(e).lower()
    print('Test 2 PASS: type mismatch detected')

# Test 3: missing FK column detected
child_df2 = pd.DataFrame({'order_id': [1, 2]})  # no user_id column
try:
    meta2.validate_schema(real_data={'users': parent_df, 'orders': child_df2})
    assert False, 'should have raised'
except SchemaValidationError as e:
    assert 'missing' in str(e).lower()
    print('Test 3 PASS: missing FK column detected')

# Test 4: collect-all — both a type mismatch and a missing column reported together
# (two FK columns on same child table)
meta3 = Metadata()
meta3.add_table('users', 'id')
meta3.add_table('products', 'prod_id')
meta3.add_table('orders', 'order_id', fk={'user_id': 'users.id', 'product_id': 'products.prod_id'})
parent_u = pd.DataFrame({'id': [1, 2]})
parent_p = pd.DataFrame({'prod_id': ['A', 'B']})
child3 = pd.DataFrame({'order_id': [1], 'user_id': [1]})  # missing product_id
try:
    meta3.validate_schema(real_data={'users': parent_u, 'products': parent_p, 'orders': child3})
    assert False, 'should have raised'
except SchemaValidationError as e:
    print('Test 4 PASS: error raised for missing column:', str(e)[:80])

# Test 5: linkage_method field on TableConfig
tc = TableConfig(pk='id')
assert tc.linkage_method == 'empirical', f'expected empirical, got {tc.linkage_method}'
tc2 = TableConfig(pk='id', linkage_method='negbinom')
assert tc2.linkage_method == 'negbinom'
print('Test 5 PASS: linkage_method defaults to empirical, accepts negbinom')

print('All tests passed.')
"
```

Expected: All 5 tests print PASS.
  </verify>
  <done>
- SchemaValidationError raised (not ValueError) for: missing parent table, type mismatch, missing FK column
- Multiple errors collected before raise — single exception lists all problems
- SchemaValidationError is instanceof SchemaError
- TableConfig.linkage_method defaults to "empirical", accepts "negbinom"
- validate_schema() with no arguments still behaves as before (backward compatible)
  </done>
</task>

</tasks>

<verification>
Run full test suite to ensure no regressions:
```bash
cd /Users/arnavdadarya/FedEx/SynthoHive && python -m pytest tests/ -x --tb=short -q 2>&1 | tail -20
```

All existing tests must continue to pass. The new exception class and extended validate_schema() are additive changes.
</verification>

<success_criteria>
- syntho_hive/exceptions.py contains SchemaValidationError as a subclass of SchemaError
- syntho_hive/interface/config.py has _dtypes_compatible() helper and extended validate_schema(real_data=None)
- TableConfig has linkage_method: Literal["empirical", "negbinom"] = "empirical"
- validate_schema(real_data={...}) detects type mismatches, missing FK columns, and missing parent tables — collecting all before raising
- pytest tests/ passes with no regressions
</success_criteria>

<output>
After completion, create `.planning/phases/02-relational-correctness/02-01-SUMMARY.md`
</output>
